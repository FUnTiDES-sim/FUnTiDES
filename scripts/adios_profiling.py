#!/usr/bin/env python3
"""
ADIOS2 BP5 Profiling Visualization Script
==========================================

PURPOSE:
--------
This script analyzes and visualizes profiling data generated by ADIOS2 BP5 engine
during parallel I/O operations in SEMproxy acoustic simulations.

WHAT IT DOES:
-------------
1. Reads the profiling.json file generated by ADIOS2 BP5 with Profile="On"
2. Extracts timing information for:
   - ES (EndStep) operations and sub-operations
   - BS (BeginStep) operations
   - DC (Data Copy) operations
   - Transport layer operations (POSIX file I/O)
3. Computes statistics: total time, call count, average time per operation
4. Generates both text summary and multi-panel visualizations
5. Analyzes transport performance (actual disk writes)

BP5 PROFILING FORMAT:
---------------------
The JSON contains an array of rank data with this structure:
- ES: EndStep total time
- BS: BeginStep operations
- DC: Data Copy operations
- ES_meta1/ES_meta2: Metadata operations
- ES_close: File close operations
- ES_AWD: Async Write Done
- transport_N: Individual transport layers (POSIX files)
  - wbytes: Bytes written
  - write/open/close: Operation timings

Each operation has:
- _mus: Total time in microseconds
- Object with {mus: time, nCalls: count}

INPUT:
------
- profiling.json: JSON array with per-rank profiling data from ADIOS2 BP5

OUTPUT:
-------
1. Console: Detailed timing tables and transport statistics
2. adios2_profiling_analysis.png: Multi-panel visualization (1500x1000px, 300DPI)

USAGE:
------
    python3 analyze_bp5_profile.py profiling.json

REQUIREMENTS:
-------------
- Python 3.6+
- pandas, matplotlib

Install: pip install pandas matplotlib

INTERPRETATION FOR SEM SIMULATIONS:
------------------------------------
- High ES_close time: File system sync overhead (use faster storage)
- High transport write time: I/O bandwidth bottleneck
- Many BS_WaitOnAsync: Previous async operations not completing fast enough
- Large wbytes with low write time: Good I/O performance
- ES_AWD time: Time waiting for async writes to complete

OPTIMIZATION TIPS:
------------------
- If ES_close dominates: Increase aggregation, use burst buffers
- If transport write is slow: Check storage bandwidth, use parallel file system
- If too many small writes: Batch data, increase buffer sizes
- High wait times: Adjust ADIOS2 async parameters

"""

import json
import pandas as pd
import matplotlib.pyplot as plt
import sys

def analyze_bp5_profile(json_file):
    """
    Analyze ADIOS2 BP5 profiling data with the specific format used.
    """
    with open(json_file, 'r') as f:
        data = json.load(f)

    print("=" * 70)
    print("ADIOS2 BP5 Profiling Analysis")
    print("=" * 70)

    # BP5 format is an array of rank data
    if not isinstance(data, list):
        print("Error: Expected array of rank data")
        return None

    # Aggregate data across all ranks
    all_operations = {}
    transport_stats = {}

    for rank_idx, rank_data in enumerate(data):
        rank = rank_data.get('rank', rank_idx)

        print(f"\n--- Rank {rank} ---")
        print(f"Start time: {rank_data.get('start', 'N/A')}")

        # Process each operation
        for key, value in rank_data.items():
            # Skip metadata fields
            if key in ['rank', 'start', 'databytes', 'metadatabytes', 'metametadatabytes']:
                continue

            # Handle transport layers separately
            if key.startswith('transport_'):
                if key not in transport_stats:
                    transport_stats[key] = {
                        'type': value.get('type', 'Unknown'),
                        'total_bytes': 0,
                        'operations': {}
                    }
                transport_stats[key]['total_bytes'] += value.get('wbytes', 0)

                for op in ['write', 'open', 'close']:
                    if op in value and isinstance(value[op], dict):
                        if op not in transport_stats[key]['operations']:
                            transport_stats[key]['operations'][op] = {'mus': 0, 'nCalls': 0}
                        transport_stats[key]['operations'][op]['mus'] += value[op].get('mus', 0)
                        transport_stats[key]['operations'][op]['nCalls'] += value[op].get('nCalls', 0)
                continue

            # Handle regular operations (those ending in _mus are summaries)
            if key.endswith('_mus'):
                op_name = key[:-4]  # Remove _mus suffix

                # Get the detailed object
                if op_name in rank_data and isinstance(rank_data[op_name], dict):
                    op_data = rank_data[op_name]

                    if op_name not in all_operations:
                        all_operations[op_name] = {'mus': 0, 'nCalls': 0}

                    all_operations[op_name]['mus'] += op_data.get('mus', 0)
                    all_operations[op_name]['nCalls'] += op_data.get('nCalls', 0)

    # Create DataFrame for operations
    timing_data = []
    for op_name, metrics in all_operations.items():
        total_us = metrics['mus']
        calls = metrics['nCalls']
        avg_us = total_us / calls if calls > 0 else 0

        timing_data.append({
            'Operation': op_name,
            'Total (μs)': total_us,
            'Total (ms)': total_us / 1000,
            'Count': calls,
            'Avg (μs)': avg_us,
            'Avg (ms)': avg_us / 1000
        })

    df = pd.DataFrame(timing_data)
    df = df.sort_values('Total (μs)', ascending=False)

    # Print operation summary
    print("\n" + "=" * 70)
    print("OPERATION TIMING SUMMARY")
    print("=" * 70)
    print(df[['Operation', 'Total (ms)', 'Count', 'Avg (ms)']].to_string(index=False))
    print(f"\nTotal I/O Time: {df['Total (μs)'].sum() / 1e6:.3f} seconds")

    # Print transport statistics
    print("\n" + "=" * 70)
    print("TRANSPORT LAYER STATISTICS")
    print("=" * 70)
    for transport_name, stats in transport_stats.items():
        print(f"\n{transport_name} ({stats['type']}):")
        print(f"  Total bytes written: {stats['total_bytes']:,} bytes ({stats['total_bytes']/1024/1024:.2f} MB)")

        for op_name, op_stats in stats['operations'].items():
            total_ms = op_stats['mus'] / 1000
            calls = op_stats['nCalls']
            avg_ms = total_ms / calls if calls > 0 else 0
            print(f"  {op_name}: {total_ms:.3f} ms ({calls} calls, {avg_ms:.3f} ms avg)")

            if op_name == 'write' and stats['total_bytes'] > 0:
                bandwidth = stats['total_bytes'] / (op_stats['mus'] / 1e6) / 1024 / 1024  # MB/s
                print(f"    → Bandwidth: {bandwidth:.2f} MB/s")

    # Create visualizations
    if len(df) > 0:
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))

        # 1. Total time by operation
        top_ops = df.head(10)
        axes[0, 0].barh(top_ops['Operation'], top_ops['Total (ms)'])
        axes[0, 0].set_xlabel('Time (ms)')
        axes[0, 0].set_title('Operations by Total Time')
        axes[0, 0].invert_yaxis()
        axes[0, 0].grid(axis='x', alpha=0.3)

        # 2. Average time per call
        axes[0, 1].barh(top_ops['Operation'], top_ops['Avg (ms)'])
        axes[0, 1].set_xlabel('Average Time (ms)')
        axes[0, 1].set_title('Average Time per Operation Call')
        axes[0, 1].invert_yaxis()
        axes[0, 1].grid(axis='x', alpha=0.3)

        # 3. Call frequency
        axes[1, 0].barh(top_ops['Operation'], top_ops['Count'])
        axes[1, 0].set_xlabel('Number of Calls')
        axes[1, 0].set_title('Operation Call Frequency')
        axes[1, 0].invert_yaxis()
        axes[1, 0].grid(axis='x', alpha=0.3)

        # 4. Time distribution pie chart
        axes[1, 1].pie(top_ops['Total (μs)'],
                       labels=top_ops['Operation'],
                       autopct='%1.1f%%',
                       startangle=90)
        axes[1, 1].set_title('Time Distribution Across Operations')

        plt.suptitle('ADIOS2 BP5 I/O Profiling Analysis', fontsize=16, y=0.995)
        plt.tight_layout()
        plt.savefig('adios2_profiling_analysis.png', dpi=300, bbox_inches='tight')
        print("\nVisualization saved to: adios2_profiling_analysis.png")
        plt.show()

    return df, transport_stats

if __name__ == "__main__":
    json_file = sys.argv[1] if len(sys.argv) > 1 else 'profiling.json'

    print(f"Analyzing ADIOS2 BP5 profiling data from: {json_file}\n")

    try:
        df, transport = analyze_bp5_profile(json_file)

        if df is not None:
            print("\n" + "=" * 70)
            print("ANALYSIS COMPLETE")
            print("=" * 70)
            print("\nKey Insights:")

            # Find dominant operation
            if len(df) > 0:
                top_op = df.iloc[0]
                print(f"- Dominant operation: {top_op['Operation']} ({top_op['Total (ms)']:.2f} ms)")

                # Check for specific bottlenecks
                es_close = df[df['Operation'] == 'ES_close']
                if not es_close.empty and es_close.iloc[0]['Total (ms)'] > 100:
                    print(f"- High ES_close time detected: Consider faster storage or async I/O")

                total_time = df['Total (μs)'].sum() / 1000
                print(f"- Total I/O overhead: {total_time:.2f} ms")

    except FileNotFoundError:
        print(f"Error: File '{json_file}' not found.")
        sys.exit(1)
    except json.JSONDecodeError as e:
        print(f"Error: Invalid JSON - {e}")
        sys.exit(1)
    except Exception as e:
        print(f"Unexpected error: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
